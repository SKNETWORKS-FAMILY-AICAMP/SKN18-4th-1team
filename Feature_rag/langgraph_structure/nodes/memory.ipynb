{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b123ec",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc0160f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env 로드\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 스크립트 실행 위치 기준 두 단계 상위 폴더\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "load_dotenv(os.path.join(root_path, \".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81ea79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387929a",
   "metadata": {},
   "source": [
    "## Message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c129edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62a479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "from langgraph_structure.init_state import GraphState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62abf1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import create_engine\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51bf0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(os.getenv(\"CONNECTION_STRING\"))\n",
    "\n",
    "def memory_node_to_db(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    검색 결과와 LLM 응답을 PostgreSQL(DB)에 그대로 저장\n",
    "    \"\"\"\n",
    "    search_results = state.get(\"hospitals\", [])\n",
    "    llm_response = state.get(\"llm_answer\", \"\")\n",
    "\n",
    "    # JSON 형태로 직렬화\n",
    "    search_results_json = json.dumps(search_results, ensure_ascii=False)\n",
    "\n",
    "    # 테이블 생성 (없으면)\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS memory (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            search_results JSONB,\n",
    "            llm_response TEXT,\n",
    "            created_at TIMESTAMP DEFAULT NOW()\n",
    "        )\n",
    "        \"\"\"))\n",
    "\n",
    "        # 데이터 삽입\n",
    "        conn.execute(\n",
    "            text(\"\"\"\n",
    "            INSERT INTO memory (search_results, llm_response)\n",
    "            VALUES (:search_results, :llm_response)\n",
    "            \"\"\"),\n",
    "            {\"search_results\": search_results_json, \"llm_response\": llm_response}\n",
    "        )\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee787f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
